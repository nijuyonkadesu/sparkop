# Pyspark workshop ~


## Installation of pyspark in windows
follow [this](https://medium.com/@dipan.saha/getting-started-with-pyspark-day-1-37e5e6fdc14b) and try that sample program

## Nice findings
- sc <- spark context [used to perform distributed operation, processing in parallel, writing to external storage]
